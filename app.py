import streamlit as st
import fitz  # PyMuPDF
import io
from PIL import Image
from sentence_transformers import SentenceTransformer
import faiss
import numpy as np
from transformers import pipeline
from pythainlp.tokenize import word_tokenize

st.set_page_config(page_title="PDF AI Q&A App", layout="wide")
st.title("üìÑ ‡πÅ‡∏≠‡∏õ‡∏≠‡πà‡∏≤‡∏ô PDF + ‡∏ñ‡∏≤‡∏°‡∏ï‡∏≠‡∏ö‡∏î‡πâ‡∏ß‡∏¢ AI")

uploaded_file = st.file_uploader("üì§ ‡∏≠‡∏±‡∏õ‡πÇ‡∏´‡∏•‡∏î‡πÑ‡∏ü‡∏•‡πå PDF", type="pdf")

@st.cache_resource
def load_model():
    return SentenceTransformer('all-MiniLM-L6-v2')

@st.cache_resource
def load_qa_model():
    return pipeline("question-answering", model="distilbert-base-cased-distilled-squad")

model = load_model()
qa_model = load_qa_model()

all_lines = []
page_map = []

def jaccard_similarity(list1, list2):
    set1 = set(list1)
    set2 = set(list2)
    intersection = set1.intersection(set2)
    union = set1.union(set2)
    if not union:
        return 0
    return len(intersection) / len(union)

if uploaded_file:
    doc = fitz.open(stream=uploaded_file.read(), filetype="pdf")

    for page_number in range(len(doc)):
        page = doc[page_number]
        text = page.get_text()

        for line in text.splitlines():
            clean_line = line.strip()
            if clean_line:
                all_lines.append(clean_line)
                page_map.append(page_number + 1)

        st.subheader(f"üìÑ ‡∏´‡∏ô‡πâ‡∏≤ {page_number + 1}")
        if text.strip():
            st.text_area("üìö ‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡πÉ‡∏ô‡∏´‡∏ô‡πâ‡∏≤‡∏ô‡∏µ‡πâ", text, height=200)
        else:
            st.warning("‚ö†Ô∏è ‡πÑ‡∏°‡πà‡∏û‡∏ö‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡πÉ‡∏ô‡∏´‡∏ô‡πâ‡∏≤‡∏ô‡∏µ‡πâ")

        images = page.get_images(full=True)
        if images:
            st.write("üñºÔ∏è ‡∏†‡∏≤‡∏û‡πÉ‡∏ô‡∏´‡∏ô‡πâ‡∏≤‡∏ô‡∏µ‡πâ:")
            for img_index, img in enumerate(images):
                xref = img[0]
                base_image = doc.extract_image(xref)
                image_bytes = base_image["image"]
                image = Image.open(io.BytesIO(image_bytes))
                st.image(image, caption=f"‡∏†‡∏≤‡∏û‡∏ó‡∏µ‡πà {img_index + 1}", use_container_width=True)
        else:
            st.info("‡πÑ‡∏°‡πà‡∏°‡∏µ‡∏†‡∏≤‡∏û‡πÉ‡∏ô‡∏´‡∏ô‡πâ‡∏≤‡∏ô‡∏µ‡πâ")

    if all_lines:
        st.markdown("---")
        st.header("‚ùì ‡∏ñ‡∏≤‡∏°-‡∏ï‡∏≠‡∏ö‡∏à‡∏≤‡∏Å‡πÄ‡∏ô‡∏∑‡πâ‡∏≠‡∏´‡∏≤ PDF ‡∏î‡πâ‡∏ß‡∏¢ AI")
        user_question = st.text_input("üí¨ ‡∏û‡∏¥‡∏°‡∏û‡πå‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°‡∏Ç‡∏≠‡∏á‡∏Ñ‡∏∏‡∏ì‡∏ó‡∏µ‡πà‡∏ô‡∏µ‡πà")

        embeddings = model.encode(all_lines)
        dimension = embeddings.shape[1]
        index = faiss.IndexFlatL2(dimension)
        index.add(np.array(embeddings))

        if user_question:
            st.subheader("üîé ‡∏ö‡∏£‡∏£‡∏ó‡∏±‡∏î‡∏ó‡∏µ‡πà‡∏°‡∏µ‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°‡∏´‡∏£‡∏∑‡∏≠‡∏Ñ‡∏≥‡∏ó‡∏µ‡πà‡πÄ‡∏Å‡∏µ‡πà‡∏¢‡∏ß‡∏Ç‡πâ‡∏≠‡∏á:")

            # ‡∏ï‡∏±‡∏î‡∏Ñ‡∏≥‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°‡πÄ‡∏õ‡πá‡∏ô tokens
            question_tokens = word_tokenize(user_question.lower())

            matched_lines = []
            for idx, line in enumerate(all_lines):
                # ‡∏£‡∏ß‡∏°‡∏ö‡∏£‡∏£‡∏ó‡∏±‡∏î‡∏Å‡πà‡∏≠‡∏ô‡∏´‡∏ô‡πâ‡∏≤‡πÅ‡∏•‡∏∞‡∏´‡∏•‡∏±‡∏á (‡∏ñ‡πâ‡∏≤‡∏°‡∏µ) ‡∏°‡∏≤‡πÄ‡∏ä‡πá‡∏Ñ‡∏î‡πâ‡∏ß‡∏¢
                lines_to_check = [line]
                if idx > 0:
                    lines_to_check.insert(0, all_lines[idx - 1])
                if idx < len(all_lines) - 1:
                    lines_to_check.append(all_lines[idx + 1])

                # ‡∏ï‡∏±‡∏î‡∏Ñ‡∏≥‡∏Ç‡∏≠‡∏á‡∏ö‡∏£‡∏£‡∏ó‡∏±‡∏î‡∏ó‡∏µ‡πà‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î
                tokens_to_check = []
                for l in lines_to_check:
                    tokens_to_check.extend(word_tokenize(l.lower()))

                # ‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì similarity
                sim = jaccard_similarity(question_tokens, tokens_to_check)

                if sim >= 0.7:  # ‡∏°‡∏≤‡∏Å‡∏Å‡∏ß‡πà‡∏≤‡∏´‡∏£‡∏∑‡∏≠‡πÄ‡∏ó‡πà‡∏≤‡∏Å‡∏±‡∏ö 70%
                    matched_lines.append((line, page_map[idx], sim))

            if matched_lines:
                # ‡πÄ‡∏£‡∏µ‡∏¢‡∏á‡∏•‡∏≥‡∏î‡∏±‡∏ö‡∏ï‡∏≤‡∏°‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏´‡∏°‡∏∑‡∏≠‡∏ô‡∏°‡∏≤‡∏Å‡∏™‡∏∏‡∏î
                matched_lines.sort(key=lambda x: x[2], reverse=True)
                for i, (matched_line, page_num, similarity) in enumerate(matched_lines[:5]):  # ‡πÅ‡∏™‡∏î‡∏á‡∏™‡∏π‡∏á‡∏™‡∏∏‡∏î 5 ‡∏ö‡∏£‡∏£‡∏ó‡∏±‡∏î
                    st.markdown(f"**{i+1}.** (‡∏´‡∏ô‡πâ‡∏≤ {page_num}) ‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏´‡∏°‡∏∑‡∏≠‡∏ô: {similarity:.2%}")
                    st.success(matched_line)
            else:
                st.info("‡πÑ‡∏°‡πà‡∏û‡∏ö‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ó‡∏µ‡πà‡πÄ‡∏Å‡∏µ‡πà‡∏¢‡∏ß‡∏Ç‡πâ‡∏≠‡∏á‡∏Å‡∏±‡∏ö‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°")

            st.markdown("---")
            st.subheader("‚úÖ ‡∏Ñ‡∏≥‡∏ï‡∏≠‡∏ö‡∏à‡∏≤‡∏Å AI:")
            # ‡∏ô‡∏≥‡∏ö‡∏£‡∏£‡∏ó‡∏±‡∏î‡∏ó‡∏µ‡πà‡πÄ‡∏´‡∏°‡∏∑‡∏≠‡∏ô‡∏ó‡∏µ‡πà‡∏™‡∏∏‡∏î‡∏°‡∏≤‡πÉ‡∏´‡πâ AI ‡∏ï‡∏≠‡∏ö
            if matched_lines:
                context = matched_lines[0][0]
                result = qa_model(question=user_question, context=context)
                answer = result.get('answer', '‡πÑ‡∏°‡πà‡∏û‡∏ö‡∏Ñ‡∏≥‡∏ï‡∏≠‡∏ö‡∏ó‡∏µ‡πà‡∏ä‡∏±‡∏î‡πÄ‡∏à‡∏ô')
                st.success(answer)
            else:
                st.info("‡πÑ‡∏°‡πà‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡∏´‡∏≤‡∏Ñ‡∏≥‡∏ï‡∏≠‡∏ö‡∏à‡∏≤‡∏Å‡πÄ‡∏≠‡∏Å‡∏™‡∏≤‡∏£‡πÑ‡∏î‡πâ")
